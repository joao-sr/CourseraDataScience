{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Module 6 - Assignment",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction\n\nIn this notebook, we'll explore the core components of data science, including its languages, libraries, and tools. We'll also demonstrate basic arithmetic operations and outline our learning goals.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Data Science languages",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "* Python\n* R\n* SQL\n* Julia\n* Java\n* Scala\n* MATLAB\n* SAS\n* C++\n* JavaScript",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Data Science Libraries\n\n| Library      | Language | Description |\n|--------------|----------|-------------|\n| Pandas       | Python   | Data manipulation and analysis library providing data structures and operations for manipulating numerical tables and time series |\n| NumPy        | Python   | Fundamental package for scientific computing with Python, supporting large, multi-dimensional arrays and matrices |\n| SciPy        | Python   | Open-source software for mathematics, science, and engineering, building on NumPy |\n| scikit-learn | Python   | Machine learning library that provides simple and efficient tools for data mining and data analysis |\n| TensorFlow   | Python   | End-to-end open source platform for machine learning |\n| Keras        | Python   | High-level neural networks API, capable of running on top of TensorFlow, CNTK, or Theano |\n| PyTorch      | Python   | Open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing |\n| Matplotlib   | Python   | Plotting library for creating static, animated, and interactive visualizations in Python |\n| Seaborn      | Python   | Statistical data visualization library based on Matplotlib |\n| ggplot2      | R        | Data visualization package for the R programming language and its grammar of graphics |\n| dplyr        | R        | Grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges |\n| tidyr        | R        | Easily tidy data with `spread()` and `gather()` functions |\n| caret        | R        | Classification and regression training library that provides tools for data splitting, pre-processing, feature selection, model tuning using resampling, and variable importance estimation |\n| MLlib        | Spark    | Machine learning library for Apache Spark and Spark SQL |\n| H2O          | Java     | Open source, in-memory, distributed, fast, and scalable machine learning and predictive analytics platform that allows you to build machine learning models on big data |\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Data Science Tools",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "| Tool Name       | Type          | Description |\n|-----------------|---------------|-------------|\n| Jupyter Notebook| IDE           | Interactive computing environment for creating Jupyter notebooks |\n| RStudio         | IDE           | Integrated development environment for R |\n| Apache Spark    | Big Data      | Unified analytics engine for large-scale data processing |\n| Tableau         | BI            | Data visualization tool for business intelligence |\n| Microsoft Excel | Spreadsheet   | Widely-used spreadsheet tool for data analysis and visualization |\n| KNIME           | Workflow      | Open source data analytics, reporting, and integration platform |\n| RapidMiner      | Workflow      | Data science platform for machine learning, deep learning, text mining, and predictive analytics |\n| TensorFlow      | ML Framework  | Open source machine learning framework for high-performance numerical computation |\n| Hadoop          | Big Data      | Framework for distributed storage and processing of large data sets |\n| SQL Server      | Database      | Relational database management system by Microsoft |",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction to arithmetic expressions",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "2+2",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "4"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "2*3 ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "6"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# Create a code cell to convert minutes to hours.\n# Function to convert minutes to hours\ndef convert_minutes_to_hours(minutes):\n    hours = minutes / 60\n    return hours\n\n# Example usage:\nminutes = 120  # Replace with the number of minutes you want to convert\nhours = convert_minutes_to_hours(minutes)\nprint(f\"{minutes} minutes is equal to {hours} hours.\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "120 minutes is equal to 2.0 hours.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Demonstrate the ability to create and format Markdown cells within a Jupyter notebook.\n2. Showcase knowledge of data science languages and their respective libraries.\n3. Present a clear and structured overview of various data science tools.\n4. Apply basic arithmetic operations using code cells.\n5. Convert units of time (minutes to hours) programmatically.\n6. Organize content effectively to enhance readability and comprehension.\n7. Share and disseminate the notebook through a public platform like GitHub.\n8. Capture and display a screenshot of the notebook to illustrate its layout.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n\nJoao Robarts",
      "metadata": {}
    }
  ]
}